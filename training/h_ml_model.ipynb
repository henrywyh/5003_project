{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aIl-X-qX_AFc"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/harshlakhani/Desktop/Current/Projects/5003-Project/utils\n"
     ]
    }
   ],
   "source": [
    "# %cd /Users/harshlakhani/Desktop/Current/Projects/5003-Project/utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "unsupported locale setting",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlocale\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetlocale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocale\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLC_ALL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men_HK.utf8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/locale.py:610\u001b[0m, in \u001b[0;36msetlocale\u001b[0;34m(category, locale)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m locale \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(locale, _builtin_str):\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;66;03m# convert to string\u001b[39;00m\n\u001b[1;32m    609\u001b[0m     locale \u001b[38;5;241m=\u001b[39m normalize(_build_localename(locale))\n\u001b[0;32m--> 610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setlocale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocale\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mError\u001b[0m: unsupported locale setting"
     ]
    }
   ],
   "source": [
    "# locale.setlocale(locale.LC_ALL, 'en_HK.utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('en_HK', 'UTF-8')\n"
     ]
    }
   ],
   "source": [
    "# print(locale.getlocale())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lzSuPNp2_AFg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 20:42:39 WARN StopWordsRemover: Default locale set was [en_HK]; however, it was not found in available locales in JVM, falling back to en_US locale. Set param `locale` in order to respect another locale.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 20:42:43 WARN StopWordsRemover: Default locale set was [en_HK]; however, it was not found in available locales in JVM, falling back to en_US locale. Set param `locale` in order to respect another locale.\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model_path = \"../backend/models/lr_model\"\n",
    "\n",
    "pipelineModel = PipelineModel.load(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzNu90Jf_AFg",
    "outputId": "245e84bd-befc-4ee7-aa17-2aefcefa97aa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pipelineModel.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6V7tXMD_AFh"
   },
   "outputs": [],
   "source": [
    "# # receive and print messages\n",
    "# import json\n",
    "# import pandas as pd\n",
    "# from kafka import KafkaConsumer\n",
    "\n",
    "# # Define Kafka consumer\n",
    "# consumer = KafkaConsumer('machine_learning', bootstrap_servers='localhost:9092', value_deserializer=lambda m: json.loads(m.decode('utf-8')))\n",
    "\n",
    "# def process_messages():\n",
    "#     for msg in consumer:\n",
    "#         print(\"Received message:\", msg.value)  # Print received message for verification\n",
    "#         pandas_df = pd.DataFrame(msg.value)\n",
    "        \n",
    "#         # Process the received DataFrame and apply the machine learning model\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     process_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received message: {'id': '12lvtnb', 'title': 'Imma be honest'}\n",
      "23/04/14 20:43:03 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:43:03 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:43:03 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       0.0|\n",
      "+----------+\n",
      "\n",
      "Received message: {'id': '12lw1l7', 'title': 'Fellas would it be stupid to buy an xxl hoodie as a 5’4” 114 pound person….I wish I could size down but the rest is out of stock and I’m so desperate for this hoodie'}\n",
      "23/04/14 20:45:02 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:45:02 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:45:02 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       0.0|\n",
      "+----------+\n",
      "\n",
      "Received message: {'id': '12lw1je', 'title': 'we are so lucky to live in the same universe and at the same point in history as Hamilton Morris'}\n",
      "23/04/14 20:45:03 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:45:03 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:45:03 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       1.0|\n",
      "+----------+\n",
      "\n",
      "Received message: {'id': '12lw2x3', 'title': 'Why do I have to deal with male patterned baldness at 15?'}\n",
      "23/04/14 20:46:33 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:46:33 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:46:33 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       1.0|\n",
      "+----------+\n",
      "\n",
      "Received message: {'id': '12lw3kh', 'title': 'Anything you wanna know about girls'}\n",
      "23/04/14 20:47:01 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:47:01 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:47:02 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       0.0|\n",
      "+----------+\n",
      "\n",
      "Received message: {'id': '12lw3c5', 'title': 'Does anyone know how to pause life360 tracking me for no longer than an hour without sending a notification?'}\n",
      "23/04/14 20:47:02 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:47:02 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:47:02 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       1.0|\n",
      "+----------+\n",
      "\n",
      "Received message: {'id': '12lw39j', 'title': 'i might not have 99 problems'}\n",
      "23/04/14 20:47:03 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:47:03 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:47:03 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       1.0|\n",
      "+----------+\n",
      "\n",
      "Received message: {'id': '12lw4ws', 'title': 'Dunno if this is a hot take but I do not consider us as friends unless I have your socials'}\n",
      "23/04/14 20:48:31 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:48:32 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:48:32 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       0.0|\n",
      "+----------+\n",
      "\n",
      "Received message: {'id': '12lw6dr', 'title': 'good morning'}\n",
      "23/04/14 20:50:01 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:50:01 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:50:02 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       0.0|\n",
      "+----------+\n",
      "\n",
      "Received message: {'id': '12lw6ag', 'title': 'Does buying a old gaming console will make me look like a loser?'}\n",
      "23/04/14 20:50:02 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:50:02 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:50:02 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       0.0|\n",
      "+----------+\n",
      "\n",
      "Received message: {'id': '12lw71j', 'title': \"how's everyone doing?\"}\n",
      "23/04/14 20:50:31 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:50:31 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/04/14 20:50:32 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       0.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "# Define Kafka consumer\n",
    "consumer = KafkaConsumer('machine_learning', bootstrap_servers='localhost:9092', value_deserializer=lambda m: json.loads(m.decode('utf-8')))\n",
    "\n",
    "def process_messages():\n",
    "    for msgs in consumer:\n",
    "        for msg in msgs.value:\n",
    "            print(\"Received message:\", msg)  # Print received message for verification\n",
    "            df = spark.createDataFrame([(msg['title'],StringType())], ['text'])\n",
    "            pred = pipelineModel.transform(df)\n",
    "            result = pred.select('prediction').collect()[0][0]\n",
    "            print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tmgXA81F_AFh"
   },
   "outputs": [],
   "source": [
    "pred = pipelineModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uY259ei5_AFi",
    "outputId": "93f6a666-0543-4228-9b55-46220098ae40",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred.select('prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t9-IxIz9_AFi"
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.types import *\n",
    "# from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "# from pyspark.ml.feature import StringIndexer\n",
    "# from pyspark.ml.classification import LogisticRegression\n",
    "# from pyspark.ml import PipelineModel\n",
    "# from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# from turtle import textinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "syv93dbd_AFj"
   },
   "outputs": [],
   "source": [
    "# def give_me_message(text):\n",
    "#     df = spark.createDataFrame([(f'{text}', StringType())], ['text'])\n",
    "#     return df\n",
    "\n",
    "# def mental_state_detector(df):    \n",
    "#     pipelineModel = PipelineModel.load(\"../project/models/lr_model\")\n",
    "    \n",
    "# #     df = spark.createDataFrame([(f'{text}', StringType())], ['text'])\n",
    "#     pred = pipelineModel.transform(df)\n",
    "    \n",
    "#     return pred.select('prediction').collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2EDAukd8_AFj",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = give_me_message('People don\\'t die from suicide, they die from sadness.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6RUGol5_AFj",
    "outputId": "7ec5a9ba-410d-42c4-e6f3-2f5ffb0e01ea"
   },
   "outputs": [],
   "source": [
    "# mental_state_detector(df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
